{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from csv via queue and threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     121 iris_training.csv\n",
      "120,4,setosa,versicolor,virginica\n",
      "6.4,2.8,5.6,2.2,2\n",
      "5.0,2.3,3.3,1.0,1\n",
      "4.9,2.5,4.5,1.7,2\n",
      "4.9,3.1,1.5,0.1,0\n"
     ]
    }
   ],
   "source": [
    "!wc -l iris_training.csv\n",
    "!head -5 iris_training.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features Tensor(\"stack:0\", shape=(4,), dtype=float32)\n",
      "example_batch Tensor(\"shuffle_batch:0\", shape=(3, 4), dtype=float32) label_batch Tensor(\"shuffle_batch:1\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(['iris_training.csv'], num_epochs=2)\n",
    "\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, val = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.], [0.]]\n",
    "cols = (col1_sepal_length, \n",
    "        col2_sepal_width, \n",
    "        col3_petal_length, \n",
    "        col4_petal_width,\n",
    "        col5_species) = tf.decode_csv(val, record_defaults=record_defaults)\n",
    "features = tf.stack(cols[:-1])\n",
    "print 'features', features\n",
    "\n",
    "example_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [features, col5_species],\n",
    "    batch_size=3,\n",
    "    capacity=100,\n",
    "    min_after_dequeue=50)\n",
    "print 'example_batch', example_batch, 'label_batch', label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decode_csv的操作是对一行进行的\n",
    "前4列组成了features，最后一列是分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of threads 4\n"
     ]
    }
   ],
   "source": [
    "s = tf.Session()\n",
    "s.run(tf.local_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=s, coord=coord)\n",
    "print 'num of threads', len(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 有多少threads不知道是怎么控制的?\n",
    "- string_input_producer设置了num_epochs以后，需要调用local_variables_initializer，不明白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.9000001   2.4000001   3.29999995  1.        ] 1.0\n",
      "[ 4.5         2.29999995  1.29999995  0.30000001] 0.0\n",
      "[array([[ 4.4000001 ,  3.        ,  1.29999995,  0.2       ],\n",
      "       [ 6.30000019,  2.5       ,  5.        ,  1.89999998],\n",
      "       [ 4.9000001 ,  3.0999999 ,  1.5       ,  0.1       ],\n",
      "       [ 6.30000019,  2.29999995,  4.4000001 ,  1.29999995],\n",
      "       [ 4.69999981,  3.20000005,  1.60000002,  0.2       ]], dtype=float32), array([ 0.,  2.,  0.,  1.,  0.], dtype=float32)]\n",
      "[array([[ 4.9000001 ,  3.0999999 ,  1.5       ,  0.1       ],\n",
      "       [ 6.69999981,  3.        ,  5.        ,  1.70000005],\n",
      "       [ 5.0999999 ,  3.79999995,  1.5       ,  0.30000001],\n",
      "       [ 4.69999981,  3.20000005,  1.29999995,  0.2       ],\n",
      "       [ 5.9000001 ,  3.        ,  5.0999999 ,  1.79999995]], dtype=float32), array([ 0.,  1.,  0.,  0.,  2.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(2):\n",
    "    example, label = s.run([features, col5_species])\n",
    "    print example, label\n",
    "\n",
    "for i in xrange(2):\n",
    "    print s.run([example_batch, label_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为decode_csv是对行进行操作的，所以每次run就返回文件中的一行\n",
    "而example_batch每次返回一批数据，还会shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................\n",
      "total 240\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "n = 0\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        X, y_ = s.run([example_batch, label_batch])\n",
    "        n += X.shape[0]\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print  # reach epoch limits\n",
    "print 'total', n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
